This directory has files used by the M4 - Language Modeling lab
This lab covers the following topics:
. Defining a top-N vocabulary from training data
. Computing N-gram counts
. Estimating backoff N-grams, understanding the backoff rule
. Computing perplexity, OOV rates
. Perplexity as a function of training data size
. Interpolating two models
. Pruning of an N-gram model, perplexity as a function of model size
